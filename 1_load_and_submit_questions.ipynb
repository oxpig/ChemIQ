{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0fc6535-eeb8-4633-a9c2-01cafaea21b1",
   "metadata": {},
   "source": [
    "# Notebook for loading and submitting questions\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c8d7d-e55b-4a37-8d76-ab15460f738d",
   "metadata": {},
   "source": [
    "## Question JSON Format\n",
    "\n",
    "Each question is a Python dict with the following keys:\n",
    "\n",
    "- **uuid**: unique identifier\n",
    "- **ChemIQ**: Boolean whether question is part of main ChemIQ benchmark\n",
    "- **question_category**, **sub_category**  \n",
    "- **meta_data**: e.g. `smiles`, `smiles_random`, `carbon_count`  \n",
    "- **prompt**: the question text shown to users  \n",
    "- **answer**: the expected answer  \n",
    "- **answer_format**, **answer_range**, **verification_method**  \n",
    "\n",
    "To submit a question, send its `prompt` and keep track of the `uuid`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e628aa1-9c5b-4104-9bed-d4fc5be21e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# Load all questions\n",
    "lines = Path('questions/chemiq.jsonl').read_text(encoding='utf-8').splitlines()\n",
    "data = [json.loads(line) for line in lines]\n",
    "\n",
    "# Summarise totals\n",
    "total = len(data)\n",
    "counts = Counter()\n",
    "for q in data:\n",
    "    counts[(q['question_category'],q['sub_category'])] += 1\n",
    "\n",
    "print(f\"Total questions (n={total}):\")\n",
    "for (category, sub_category), count in sorted(counts.items()):\n",
    "    print(f\" - {category!r}, {sub_category!r}: {count}\")\n",
    "\n",
    "chemiq_questions = [q for q in data if q.get('ChemIQ', False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf16220d-afd2-4023-a22b-d05dc1487ca1",
   "metadata": {},
   "source": [
    "## Example question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c7433-e7cd-4d20-a298-a0da00fe5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*20} PROMPT {'='*20}\")\n",
    "print(chemiq_questions[0][\"prompt\"])\n",
    "print(f\"{'='*20} ANSWER {'='*20}\")\n",
    "print(chemiq_questions[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ef48b-c472-4821-94b3-a914854a5164",
   "metadata": {},
   "source": [
    "# Running benchmark using OpenAI API\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b642d-5f98-46a1-beef-4b8ead026e72",
   "metadata": {},
   "source": [
    "## Create batch submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0d7122-e1cb-42f9-96de-467f0c598402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# API Batch file\n",
    "batch_submission_file = 'batch_submission_files/gpt-4o-2024-11-20-submission.jsonl'\n",
    "\n",
    "os.makedirs(os.path.dirname(batch_submission_file), exist_ok=True)\n",
    "with open(batch_submission_file, 'w') as f:\n",
    "    for question in chemiq_questions:\n",
    "        question_id = question[\"uuid\"]\n",
    "        prompt = question[\"prompt\"]\n",
    "        record = {\n",
    "            \"custom_id\": question_id,\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o-2024-11-20\",\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "print(f\"Successfully wrote batch requests to {batch_submission_file}. Number of questions = {len(chemiq_questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b695904-f7d1-4512-87dc-96922bc31102",
   "metadata": {},
   "source": [
    "## Submit batch to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb72a5-8f94-4f1d-85e7-efeac619e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set your OpenAI API key\n",
    "# This will cause an error if you have not set your OpenAI key. Either set it as an environment variable or add it below\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43716926-e632-46ba-b3a2-d783aafe02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit batch to OpenAI API\n",
    "# Uncomment if you want to submit questions. Currently commented out for safety.\n",
    "\"\"\"\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(batch_submission_file, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_id = batch_input_file.id\n",
    "created_batch = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": batch_submission_file,\n",
    "    }\n",
    ")\n",
    "print(created_batch)\n",
    "# Keep track of the Batch ID if submitting multiple different models\n",
    "print(f\"Batch ID: {created_batch.id}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83749871-bb25-4036-891d-9989ddf6a76d",
   "metadata": {},
   "source": [
    "## Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65965d-c59a-4138-a223-26f5c98703ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results_file = \"batch_output/gpt-4o-2024-11-20-results.jsonl\"\n",
    "\n",
    "# Get results\n",
    "# Uncomment to retrive submitted questions and write results (note you need to wait for completion).\n",
    "'''\n",
    "batch_result = client.batches.retrieve(created_batch.id)\n",
    "print(batch_result)\n",
    "\n",
    "if batch_result.error_file_id:\n",
    "    error_file_response = client.files.content(batch_result.error_file_id)\n",
    "\n",
    "if batch_result.output_file_id:\n",
    "    output_file_response = client.files.content(batch_result.output_file_id)\n",
    "\n",
    "    # Decode the binary content to a UTF-8 string\n",
    "    data_str = output_file_response.content.decode('utf-8')\n",
    "\n",
    "    # Split the decoded string by lines and parse each non-empty line as JSON\n",
    "    results = [json.loads(line) for line in data_str.splitlines() if line.strip()]\n",
    "\n",
    "# Write results\n",
    "os.makedirs(os.path.dirname(batch_results_file), exist_ok=True)\n",
    "with open(batch_results_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for record in results:\n",
    "        # dump each dict as a JSON string, followed by newline\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Wrote {len(results)} records to {batch_results_file}\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
