{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0fc6535-eeb8-4633-a9c2-01cafaea21b1",
   "metadata": {},
   "source": [
    "# Notebook for loading and submitting questions\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c8d7d-e55b-4a37-8d76-ab15460f738d",
   "metadata": {},
   "source": [
    "## Question JSON Format\n",
    "\n",
    "Each question is a Python dict with the following keys:\n",
    "\n",
    "- **uuid**: unique identifier\n",
    "- **ChemIQ**: Boolean whether question is part of main ChemIQ benchmark\n",
    "- **question_category**, **sub_category**  \n",
    "- **meta_data**: e.g. `smiles`, `smiles_random`, `carbon_count`  \n",
    "- **prompt**: the question text shown to users  \n",
    "- **answer**: the expected answer  \n",
    "- **answer_format**, **answer_range**, **verification_method**  \n",
    "\n",
    "To submit a question, send its `prompt` and keep track of the `uuid`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e628aa1-9c5b-4104-9bed-d4fc5be21e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions (n=796):\n",
      " - 'atom_mapping', 'random': 92\n",
      " - 'atom_mapping', 'semi-canonical': 92\n",
      " - 'counting_carbon', None: 50\n",
      " - 'counting_ring', None: 48\n",
      " - 'nmr_elucidation', 'small': 46\n",
      " - 'nmr_elucidation', 'zinc': 30\n",
      " - 'reaction', 'synthetic_canonical': 45\n",
      " - 'reaction', 'synthetic_random': 45\n",
      " - 'sar', 'integer': 20\n",
      " - 'sar', 'noise': 20\n",
      " - 'shortest_path', 'canonical': 54\n",
      " - 'shortest_path', 'random': 54\n",
      " - 'smiles_to_iupac', 'zinc_canonical': 100\n",
      " - 'smiles_to_iupac', 'zinc_random': 100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# Load all questions\n",
    "lines = Path('questions/chemiq.jsonl').read_text(encoding='utf-8').splitlines()\n",
    "data = [json.loads(line) for line in lines]\n",
    "\n",
    "# Summarise totals\n",
    "total = len(data)\n",
    "\n",
    "print(f\"Total questions (n={total}):\")\n",
    "for (category, sub_category), count in sorted(counts.items()):\n",
    "    print(f\" - {category!r}, {sub_category!r}: {count}\")\n",
    "\n",
    "chemiq_questions = [q for q in data if q.get('ChemIQ', False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf16220d-afd2-4023-a22b-d05dc1487ca1",
   "metadata": {},
   "source": [
    "## Example question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "727c7433-e7cd-4d20-a298-a0da00fe5e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== PROMPT ====================\n",
      "How many carbon atoms are in the molecule:\n",
      "\n",
      "S(c1sc(N)nn1)C(F)F\n",
      "\n",
      "Give your answer as an integer. Do not write any comments.\n",
      "==================== ANSWER ====================\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'='*20} PROMPT {'='*20}\")\n",
    "print(chemiq_questions[0][\"prompt\"])\n",
    "print(f\"{'='*20} ANSWER {'='*20}\")\n",
    "print(chemiq_questions[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ef48b-c472-4821-94b3-a914854a5164",
   "metadata": {},
   "source": [
    "# Running benchmark using OpenAI API\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b642d-5f98-46a1-beef-4b8ead026e72",
   "metadata": {},
   "source": [
    "## Create batch submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e0d7122-e1cb-42f9-96de-467f0c598402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote batch requests to batch_submission_files/gpt-4o-2024-11-20-submission.jsonl. Number of questions = 796\n"
     ]
    }
   ],
   "source": [
    "# API Batch file\n",
    "batch_submission_file = 'batch_submission_files/gpt-4o-2024-11-20-submission.jsonl'\n",
    "\n",
    "with open(batch_submission_file, 'w') as f:\n",
    "    for question in chemiq_questions:\n",
    "        question_id = question[\"uuid\"]\n",
    "        prompt = question[\"prompt\"]\n",
    "        record = {\n",
    "            \"custom_id\": question_id,\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o-2024-11-20\",\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "print(f\"Successfully wrote batch requests to {output_file}. Number of questions = {len(chemiq_questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b695904-f7d1-4512-87dc-96922bc31102",
   "metadata": {},
   "source": [
    "## Submit batch to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bbcb72a5-8f94-4f1d-85e7-efeac619e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43716926-e632-46ba-b3a2-d783aafe02b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_6800e7e2a0d4819090d713821e380203', completion_window='24h', created_at=1744889826, endpoint='/v1/chat/completions', input_file_id='file-BJzeAW7RVPFvdzLAjH1pe1', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1744976226, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'batch_submission_files/gpt-4o-2024-11-20-submission.jsonl'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(batch_submission_file, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_id = batch_input_file.id\n",
    "created_batch = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": batch_submission_file,\n",
    "    }\n",
    ")\n",
    "print(created_batch)\n",
    "# Keep track of the Batch ID if submitting multiple different models\n",
    "print(f\"Batch ID: {created_batch.id}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83749871-bb25-4036-891d-9989ddf6a76d",
   "metadata": {},
   "source": [
    "## Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c65965d-c59a-4138-a223-26f5c98703ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_6800e7e2a0d4819090d713821e380203', completion_window='24h', created_at=1744889826, endpoint='/v1/chat/completions', input_file_id='file-BJzeAW7RVPFvdzLAjH1pe1', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1744890232, error_file_id=None, errors=None, expired_at=None, expires_at=1744976226, failed_at=None, finalizing_at=1744890127, in_progress_at=1744889828, metadata={'description': 'batch_submission_files/gpt-4o-2024-11-20-submission.jsonl'}, output_file_id='file-PgbjLzDgctDmLKJLHcEkkm', request_counts=BatchRequestCounts(completed=796, failed=0, total=796))\n"
     ]
    }
   ],
   "source": [
    "batch_results_file = \"batch_results_files/gpt-4o-2024-11-20-results.jsonl\"\n",
    "\n",
    "batch_result = client.batches.retrieve(created_batch.id)\n",
    "print(batch_result)\n",
    "\n",
    "if batch_result.error_file_id:\n",
    "    error_file_response = client.files.content(batch_result.error_file_id)\n",
    "\n",
    "if batch_result.output_file_id:\n",
    "    output_file_response = client.files.content(batch_result.output_file_id)\n",
    "\n",
    "    # Decode the binary content to a UTF-8 string\n",
    "    data_str = output_file_response.content.decode('utf-8')\n",
    "\n",
    "    # Split the decoded string by lines and parse each non-empty line as JSON\n",
    "    results = [json.loads(line) for line in data_str.splitlines() if line.strip()]\n",
    "\n",
    "\"\"\"\n",
    "with open(batch_results_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for record in results:\n",
    "        # dump each dict as a JSON string, followed by newline\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Wrote {len(results)} records to {batch_results_file}\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
